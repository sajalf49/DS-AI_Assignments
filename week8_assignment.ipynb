{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajalf49/DS-AI_Assignments/blob/main/week8_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPk0rh26cR6x"
      },
      "source": [
        "# Week 8: Unsupervised Learning\n",
        "### Project: Credit Card Fraud Detection\n",
        "\n",
        "In Week 8 I applied unsupervised learning to my dataset. I used **K-Means clustering** and visualized results in 2D using **PCA**. I also evaluated clustering quality with the Silhouette score and saved the clustered dataset."
      ],
      "id": "VPk0rh26cR6x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1SynLu_cR60"
      },
      "source": [
        "## Overview of tasks I will do\n",
        "1. Load the cleaned dataset (`creditcard_cleaned.csv`) or create a small sample if it's missing.\n",
        "2. Prepare numeric features (fill missing values, scale).\n",
        "3. Run an elbow analysis to choose number of clusters (k).\n",
        "4. Fit K-Means, assign cluster labels.\n",
        "5. Reduce dimensionality to 2D with PCA and plot clusters.\n",
        "6. Compute Silhouette score and save the dataset with cluster labels.\n"
      ],
      "id": "a1SynLu_cR60"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVCKrpicR62"
      },
      "outputs": [],
      "source": [
        "# Imports and settings\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid')\n"
      ],
      "id": "RCVCKrpicR62",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jN_ACcPcR64"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load dataset (use cleaned dataset from Week 2 if available)\n",
        "csv_name = 'creditcard_cleaned.csv'\n",
        "if os.path.exists(csv_name):\n",
        "    df = pd.read_csv(csv_name)\n",
        "    print(f\"Loaded '{csv_name}' (shape: {df.shape})\")\n",
        "else:\n",
        "    print(f\"'{csv_name}' not found â€” creating a sample dataset for clustering.\")\n",
        "    data = {\n",
        "        'TransactionID': list(range(1, 51)),\n",
        "        'Amount': np.concatenate([np.random.normal(100, 50, 40), np.random.normal(1000, 300, 10)]) .tolist(),\n",
        "        'Age': np.random.randint(18, 70, size=50).tolist(),\n",
        "        'Fraudulent': np.random.choice([0,0,0,1], size=50).tolist()\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    print(f\"Sample '{csv_name}' created (shape: {df.shape})\")\n",
        "\n",
        "df.head()"
      ],
      "id": "_jN_ACcPcR64",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrk_ryAEcR65"
      },
      "source": [
        "## Step 2: Select numeric features & preprocessing\n",
        "I will use numeric columns for clustering. I fill missing values with median and scale features using StandardScaler."
      ],
      "id": "Qrk_ryAEcR65"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ZdxGH_cR65"
      },
      "outputs": [],
      "source": [
        "# Select numeric columns (exclude identifiers)\n",
        "numeric = df.select_dtypes(include=[np.number]).copy()\n",
        "if 'TransactionID' in numeric.columns:\n",
        "    numeric = numeric.drop(columns=['TransactionID'])\n",
        "\n",
        "print(\"Numeric columns used for clustering:\", list(numeric.columns))\n",
        "\n",
        "# Fill missing values with median (if any)\n",
        "numeric = numeric.fillna(numeric.median())\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(numeric)\n",
        "\n",
        "print(\"Scaled feature matrix shape:\", X_scaled.shape)\n"
      ],
      "id": "J9ZdxGH_cR65",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7XwyOKqcR65"
      },
      "source": [
        "## Step 3: Elbow method to choose k (number of clusters)\n",
        "I will compute inertia for k from 2 to 8 and plot the elbow curve to pick a reasonable k."
      ],
      "id": "Q7XwyOKqcR65"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjML7xLwcR66"
      },
      "outputs": [],
      "source": [
        "inertias = []\n",
        "K_range = range(2,9)\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_scaled)\n",
        "    inertias.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(list(K_range), inertias, '-o')\n",
        "plt.xlabel('k (number of clusters)')\n",
        "plt.ylabel('Inertia (within-cluster sum of squares)')\n",
        "plt.title('Elbow Method for choosing k')\n",
        "plt.xticks(list(K_range))\n",
        "plt.show()\n",
        "\n",
        "print('Inertias:', dict(zip(K_range, inertias)))"
      ],
      "id": "qjML7xLwcR66",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPXJPsBQcR66"
      },
      "source": [
        "ðŸ‘‰ **I inspect the elbow plot** and choose a k where the inertia reduction starts to plateau. For this notebook I will pick `k = 3` as a reasonable starting point (you can change it after inspecting the plot)."
      ],
      "id": "MPXJPsBQcR66"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP0PmkCFcR67"
      },
      "outputs": [],
      "source": [
        "# Step 4: Fit K-Means with chosen k and attach labels\n",
        "k = 3\n",
        "kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "df_clusters = df.copy()\n",
        "df_clusters['cluster'] = cluster_labels\n",
        "print('Cluster counts:')\n",
        "print(df_clusters['cluster'].value_counts().sort_index())\n"
      ],
      "id": "uP0PmkCFcR67",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "130DbEDbcR67"
      },
      "source": [
        "## Step 5: PCA to 2D & Visualization\n",
        "I reduce the scaled features to 2 principal components and plot the clusters in 2D. This helps me visually inspect cluster separation."
      ],
      "id": "130DbEDbcR67"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ULF6DxcR67"
      },
      "outputs": [],
      "source": [
        "# PCA to 2 components\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "df_clusters['pca1'] = X_pca[:,0]\n",
        "df_clusters['pca2'] = X_pca[:,1]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "palette = sns.color_palette('tab10', n_colors=k)\n",
        "sns.scatterplot(data=df_clusters, x='pca1', y='pca2', hue='cluster', palette=palette, s=80)\n",
        "plt.title('K-Means clusters visualized in 2D PCA space')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend(title='cluster')\n",
        "plt.show()\n"
      ],
      "id": "y0ULF6DxcR67",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r72nlLpfcR67"
      },
      "source": [
        "### Optional: show cluster centers in PCA space\n",
        "I convert cluster centers (which are in scaled feature space) to PCA space and plot them as X markers."
      ],
      "id": "r72nlLpfcR67"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb9HmPr7cR68"
      },
      "outputs": [],
      "source": [
        "centers_scaled = kmeans.cluster_centers_\n",
        "centers_pca = pca.transform(centers_scaled)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=df_clusters, x='pca1', y='pca2', hue='cluster', palette=palette, s=80, alpha=0.6)\n",
        "plt.scatter(centers_pca[:,0], centers_pca[:,1], marker='X', s=200, c='black', label='centers')\n",
        "plt.title('Clusters and cluster centers (PCA space)')\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "Sb9HmPr7cR68",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zkRNbfzcR68"
      },
      "source": [
        "## Step 6: Evaluate clustering quality (Silhouette score)\n",
        "Silhouette score ranges from -1 to 1; higher is better. It measures how similar an object is to its own cluster compared to other clusters."
      ],
      "id": "3zkRNbfzcR68"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inKrzcJ5cR68"
      },
      "outputs": [],
      "source": [
        "if len(set(cluster_labels)) > 1:\n",
        "    sil_score = silhouette_score(X_scaled, cluster_labels)\n",
        "    print(f\"Silhouette score for k={k}: {sil_score:.3f}\")\n",
        "else:\n",
        "    print('Only one cluster found â€” silhouette score not defined.')\n"
      ],
      "id": "inKrzcJ5cR68",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVHE4KJEcR69"
      },
      "source": [
        "## Step 7: Inspect cluster characteristics\n",
        "I compute summary statistics per cluster (mean Amount, mean Age, count) to understand cluster behavior."
      ],
      "id": "mVHE4KJEcR69"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZJSsu2xcR69"
      },
      "outputs": [],
      "source": [
        "cluster_summary = df_clusters.groupby('cluster').agg(\n",
        "    count=('cluster','size'),\n",
        "    mean_amount=('Amount','mean'),\n",
        "    median_amount=('Amount','median'),\n",
        "    mean_age=('Age','mean')\n",
        ").reset_index()\n",
        "cluster_summary"
      ],
      "id": "4ZJSsu2xcR69",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB09MaKycR69"
      },
      "source": [
        "ðŸ‘‰ **Insight:** I look for clusters with higher average `Amount` or other distinguishing traits â€” such clusters could highlight suspicious behavior worth investigating further."
      ],
      "id": "dB09MaKycR69"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXM-0sLucR69"
      },
      "outputs": [],
      "source": [
        "# Step 8: Save clustered dataset for the repo\n",
        "out_csv = 'creditcard_clusters.csv'\n",
        "df_clusters.to_csv(out_csv, index=False)\n",
        "print(f\"Saved clustered dataset as '{out_csv}' (shape: {df_clusters.shape})\")\n"
      ],
      "id": "JXM-0sLucR69",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWkwrgUXcR6-"
      },
      "source": [
        "## Conclusion / Project Milestone\n",
        "- I applied K-Means clustering and visualized clusters in 2D using PCA.  \n",
        "- I computed the Silhouette score to get a quick sense of cluster quality.  \n",
        "- I saved the dataset with cluster labels as `creditcard_clusters.csv` for further analysis.  \n",
        "\n",
        "**Next steps:** use clusters to help with feature engineering (create cluster membership feature), or apply anomaly detection methods to the high-value/sparse clusters."
      ],
      "id": "KWkwrgUXcR6-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}